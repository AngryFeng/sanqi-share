# Linux 多核处理器的缓存一致性

## 0.多核与缓存行

>  数组中的不简单代码

![缓存一致性-不简单代码1](.\素材\缓存一致性-不简单代码1.png)

```c
#include <pthread.h>
#include <stdlib.h>
#include <sys/time.h>
#include <stdio.h>

int num_threads = 4;
int scale = 16;
//int scale = 1;
int size = 200000000;

int* balance;

void *mythread(void *arg) {
    int tid = *(int *)arg;
    tid *= scale;

    for (int i = 0; i < size; i++) {
        balance[tid]++;
    }

    printf("Balance is %d\n", balance[tid]);
    free(arg); // 释放动态分配的tid
    return NULL;
}

int main(int argc, char *argv[]) {
    struct timeval tstart, tend;
    double exectime;
    pthread_t *threads = malloc(num_threads * sizeof(pthread_t));
    balance = malloc(num_threads * sizeof(int) * scale);

    gettimeofday(&tstart, NULL);
    for (int i = 0; i < num_threads; ++i) {
        int *tid = malloc(sizeof(int));
        *tid = i;
        pthread_create(&threads[i], NULL, mythread, tid);
    }

    for (int i = 0; i < num_threads; ++i) {
        pthread_join(threads[i], NULL);
    }
    gettimeofday(&tend, NULL);

    exectime = (tend.tv_sec - tstart.tv_sec) * 1000.0;
    exectime += (tend.tv_usec - tstart.tv_usec) / 1000.0;

    printf("Sizeof(int) = %lu\n", sizeof(int)); // 使用%lu避免警告
    printf("Number of threads: %d\tExecution time:%.3lf sec\n", num_threads, exectime / 1000.0);

    free(threads);
    free(balance);
    return 0;
}
```

Q&A：以上代码场景中，在scale分别为1和16时，程序运行时间有没有很大差别，为什么？

>  结构体中的不简单代码

```c
#include <pthread.h>
#include <stdlib.h>
#include <sys/time.h>
#include <stdio.h>

int size = 200000000;

struct {
    int a; // thread_0

    int b; // thread_1
    char c[64];
} data;

void *thread_0(void *arg) {
    int result;
    for(int i = 0; i < size; i++) {
      result = data.a;
     //   data.a = 0;
    }
}
void *thread_1(void *arg) {
    int result;
    for(int i = 0; i < size; i++) {
        result = data.b;
//        data.b = 1;
    }
}

int main(int argc, char *argv[]) {
    struct timeval tstart, tend;
    double exectime;
    pthread_t id0, id1;

    gettimeofday(&tstart, NULL);

    pthread_create(&id0, NULL, thread_0, NULL);
    pthread_create(&id1, NULL, thread_1, NULL);

    pthread_join(id0, NULL);
    pthread_join(id1, NULL);

    gettimeofday(&tend, NULL);


    exectime = (tend.tv_sec - tstart.tv_sec) * 1000.0; // sec to ms
    exectime += (tend.tv_usec - tstart.tv_usec) / 1000.0; // us to ms

    printf("Execution time:%.3lf sec\n", exectime / 1000.0);

    return 0;
}
```

Q&A：以上代码场景中，下面两段代码谁快

![缓存一致性-结构体写](.\素材\缓存一致性-结构体写.png)

Q&A：以上代码场景中，下面两段代码谁快

![缓存一致性-结构体读](.\素材\缓存一致性-结构体读.png)

> 缓存行

CPU 速度极快，而内存速度相对缓慢。为了减少等待数据的时间，CPU 设置了高速缓存（Cache）作为临时数据仓库。但CPU不会逐个字节地从内存搬运数据，而是以固定大小的块为单位进行批量搬运，这个块就称为“缓存行”（Cache Line），通常大小为 64 字节。这种机制基于“空间局部性”原理，即CPU很可能马上会访问相邻的数据。一次性加载一整行，避免了频繁访问慢速内存，极大提升了效率。

## 1.从单核到多核

### 1.1 多核提高软件性能

当单核CPU的频率和架构优化触及物理瓶颈（如功耗和散热墙）后，提升性能的路径从“更快地执行单个任务”转向了“同时执行多个任务”。硬件因此转向多核架构，将多个计算核心集成到同一芯片上，通过并行处理来提升整体吞吐量。

![缓存一致性-从单核到多核](.\素材\缓存一致性-从单核到多核.png)

### 1.2 多核有代价

![缓存一致性-多核不是免费午餐](.\素材\缓存一致性-多核不是免费午餐.png)

多核架构并非性能的万能解药，它引入了单核时代不曾有过的复杂挑战，主要体现在数据正确性和性能可扩展性两个方面。

> 正确性保证

核心矛盾在于多个执行流对共享数据的并发访问。当多个核同时读写同一内存位置（如一个全局变量）时，如果没有恰当的同步保护，就会发生**竞态条件（Race Condition）**。这就像一份开放编辑的共享文档，两个用户同时下载、修改并保存，后保存者的版本会无声地覆盖前者的结果，导致数据丢失或计算错误，程序行为变得不可预测且往往致命。确保正确性必须引入锁（Lock）、原子操作等同步机制，但这本身又会带来新的性能开销和死锁风险。

> 性能保证

此问题揭示了并行性能并非随核数增长而线性提升的理论天花板。其核心障碍是**协调开销（Coordination Overhead）**。随着核数增多，核心间为保持数据一致性（缓存同步）、进行任务分配与结果汇总（通信）以及争夺共享资源（如锁、内存带宽）所花费的代价会呈指数级增长。当核数达到某个临界点后，这些管理开销甚至会超过并行计算本身带来的收益，导致增加核数后，程序的总执行时间不降反增，出现性能急剧下降的“断崖”现象。这使得许多未精心设计的应用程序无法有效利用数十甚至上百个核心。

### 1.3 多核缓存竞争导致的性能断崖

> 并行计算理论加速比（理想上限）

![缓存一致性-并行计算理论加速比](.\素材\缓存一致性-并行计算理论加速比.png)

![缓存一致性-多核应用的性能表现理想与现实](.\素材\缓存一致性-多核应用的性能表现理想与现实.png)

> 导致多核下应用性能现实与理想不符合的测试

![缓存一致性-互斥锁微基准测试](.\素材\缓存一致性-互斥锁微基准测试.png)

![缓存一致性-可扩展断崖](.\素材\缓存一致性-可扩展断崖.png)

多个线程同时执行一个函数，函数中各个线程通过CAS的方式抢占锁（操作同一缓存行）进入临界区，在核心数不断提升的时候会出现性能断崖式下降。

### 1.4 缓存层级设计影响多核协同和加速比损耗

#### 1.4.1 高速缓存层级设计

![缓存一致性-多级高速缓存](.\素材\缓存一致性-多级高速缓存.png)

越靠近CPU缓存速度越快，但是材料也越贵，通过设计多级缓存平衡这种关系

对于内存的读写，读操作逐层往下读；写操作也逐层写回。

#### 1.4.2 多核环境的缓存结构

> 多级缓存设计中在多核环境下的问题

多级缓存设计，在多核环境下，每一层级的缓存假如设计成多核共享会带来高速缓存竞争+硬件分布不均匀问题

![缓存一致性-层级缓存在多核环境下的问题](.\素材\缓存一致性-层级缓存在多核环境下的问题.png)

> 多核环境中的缓存结构

抽离L1缓存与逻辑核心绑定，抽离L2缓存与同一物理核心共享，抽离L3缓存与所有物理核心共享

![缓存一致性-多核环境的缓存结构](.\素材\缓存一致性-多核环境的缓存结构.png)

#### 1.4.3 非一致缓存访问

假如高速缓存后，对于内存数据的读写都需要各个核心通过逐层读写，不同的核心对各个层级是否与自己绑定、不同层级的访问速度不一致，会带来新的非一致缓存访问+数据一致性问题。

![缓存一致性-多核多层级缓存架构的缓存不一致](.\素材\缓存一致性-多核多层级缓存架构的缓存不一致.png)

## 2.多核缓存一致性

使用多核缓存一致性协议解决多个CPU核心的私有缓存与主内存之间的数据不一致问题

### 2.1 缓存一致性协议实现状态管理

"everything is a state machine"

> 多核处理器保证不同核心对同一内存地址视角一致

通过一套精确的消息传递规则，自动跟踪数据副本的状态（独占修改、共享、无效），并在核心写入数据时，强制使其他核心中的旧副本失效，或主动更新它们，从而确保所有核心看到的数据都是统一的、最新的视图，保证了程序的正确性。

> 缓存一致性协议依赖硬件电路设计实现状态切换和数据同步

窥探式缓存一致性协议

**目录式缓存一致性协议**

> 管理各个核心的缓存行的状态，达成一致性

![缓存一致性-解决缓存一致性问题](.\素材\缓存一致性-解决缓存一致性问题.png)

### 2.2 MSI状态转移

> 共享：可能多个核同时有缓存行的拷贝

本地可读

本地写需要迁移到独占修改，并使其他核该缓存行失效

其他核有写操作时本核该缓存行迁移到失效

![缓存一致性-共享状态](.\素材\缓存一致性-共享状态.png)

> 独占修改：该核心独占拥有缓存行

本地可读可写

其他核读需要迁移到共享

其他核写需要迁移到失效

![缓存一致性-独占修改状态](.\素材\缓存一致性-独占修改状态.png)

> 失效：本地缓存行失效

本地不能读/写缓存行

本地读需要迁移到共享，并使其他核该缓存行迁移到共享
本地写需要迁移到独占修改，并使其他核心该缓存行失效

![缓存一致性-失效状态](.\素材\缓存一致性-失效状态.png)

### 2.3 全局目录项

![缓存一致性-全局目录项](.\素材\缓存一致性-全局目录项.png)

缓存行记录地址+状态+值
增加全局目录项，记录每条缓存行的脏位+向量位

### 2.4 目录式缓存一致性：示例

![缓存一致性-目录式缓存一致性示例](.\素材\缓存一致性-目录式缓存一致性示例.png)

```text
CPU0执行 STR X, 233
查看目录项，设置脏位，更改拥有者
更新CPU1, CPU2目录项，使其失效
回复CPU0通知其可以独占修改
```

状态机切换成
![缓存一致性-目录式示例状态切换1](.\素材\缓存一致性-目录式示例状态切换1.png)

```text
CPU1 执行 STR X, 888
查看目录项，修改脏位，更改拥有者
更新CPU0目录项，使其失效
回复CPU1，可以独占修改
```

状态机切换成

![缓存一致性-目录式示例状态切换2](.\素材\缓存一致性-目录式示例状态切换2.png)

```text
CPU0 执行 LDR X
发现失效，去目录找谁拥有
更新目录，并让拥有者给cpu0发送最新的值，迁移状态
CPU1转发最新的值给CPU2
```

状态机切换成

![缓存一致性-目录式示例状态切换3](.\素材\缓存一致性-目录式示例状态切换3.png)

### 2.5 可扩展性断崖：锁竞争损耗

![缓存一致性-回到可扩展性断崖](.\素材\缓存一致性-回到可扩展性断崖.png)

![缓存一致性-可扩展性断崖原因png](.\素材\缓存一致性-可扩展性断崖原因png.png)

当多核通过CAS的方式抢占锁时，由于缓存一致性协议的存在，随着核数的增长，产生的额外缓存同步会指数级上涨，从而导致性能断崖

## 3 多核缓存一致性锁竞争优化

> 锁竞争时回退策略

锁回退策略，具体做法是对所发生争抢时，让各个核心随机空跑一定的时间片，从而避免对单一缓存行的高度竞争。

问题：随机的时间片要如何随机？延缓了获取到锁的时机。

> MCS锁

MCS锁是一种基于队列的自旋锁，旨在解决多核环境下传统自旋锁的缓存一致性风暴问题。

其核心是为每个申请锁的线程创建一个本地节点并加入队列。线程不在一个全局变量上自旋，而是在**自己节点的本地变量**上自旋等待。当前锁持有者释放时，会找到队列中的下一个节点，并设置该节点的状态为可运行，从而直接通知下一个等待者。

这种方式消除了所有线程同时竞争、刷新同一内存位置带来的缓存行失效开销，极大地提升了可扩展性，尤其适合高性能多核场景。

**核心思路：在关键路径上避免对单一缓存行的高度竞争**

![缓存一致性-mcs锁设计思路](.\素材\缓存一致性-mcs锁设计思路.png)

数据结构

![缓存一致性-MCS锁结构](.\素材\缓存一致性-MCS锁结构.png)

当一个线程尝试抢占锁时，它首先会快速尝试原子操作（如CAS）来获取锁。若成功，则立即进入临界区执行。

若获取失败，表明锁已被占用。线程通常会进入**自旋等待**（反复检查锁状态）或**阻塞挂起**（让出CPU，进入睡眠状态）的模式，并将自己加入该锁的等待队列中。

当持有锁的线程执行完临界区代码并释放锁时，它会通知等待队列，唤醒其中一个或多个等待线程（如队首线程）。被唤醒的线程会再次尝试获取锁，成功者即可进入临界区执行后续任务，从而完成一次完整的锁周期。

## 4 多核缓存一致性的伪共享

![缓存一致性-伪共享](.\素材\缓存一致性-伪共享.png)

## 3.系统软件开发者视角下的缓存一致性

![缓存一致性-系统软件开发者视角的缓存一致性png](.\素材\缓存一致性-系统软件开发者视角的缓存一致性png.png)

-------------------------------------------------------------------------------------

参考文献：

https://ycnw11in464y.feishu.cn/file/Jvnib4xGToYjg8xruxlcy9QNncd

《操作系统：原理与实现》